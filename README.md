üöÄ Ejercicio de Capacitaci√≥n: Asistente Inteligente de Soporte T√©cnico

Contexto del Problema (La Problem√°tica) üìù

Imagina que trabajas para una empresa de software que vende un producto muy popular. El equipo de soporte t√©cnico recibe cientos de correos electr√≥nicos y tickets de usuarios todos los d√≠as con preguntas, problemas y dudas.

El problema es que muchos de estos tickets son repetitivos y consumen mucho tiempo del equipo, que podr√≠a estar resolviendo problemas m√°s complejos. La gerencia ha decidido implementar una primera l√≠nea de defensa con IA para automatizar las respuestas a las preguntas m√°s frecuentes.

Objetivo del Ejercicio üéØ

Tu misi√≥n es desarrollar un script en Python que act√∫e como un "Asistente de Soporte Inteligente". Este script debe ser capaz de recibir una pregunta de un usuario sobre un problema t√©cnico y, utilizando un contexto predefinido (un peque√±o manual o base de conocimiento), generar una respuesta √∫til y amigable para el usuario.

El objetivo es que el asistente pueda responder preguntas como:

    "¬øC√≥mo puedo resetear mi contrase√±a?"

    "Mi programa no abre, ¬øqu√© hago?"

    "¬øCu√°les son los requisitos del sistema para instalar el software?"

Herramientas y Librer√≠as Requeridas üõ†Ô∏è

Para este ejercicio, deber√°s utilizar las siguientes herramientas:

    Python

    LangChain: Para orquestar el flujo de la informaci√≥n (pregunta -> prompt -> modelo -> respuesta).

    LangChain Google Vertex AI: Para conectar con el modelo de IA de Gemini.

Requisitos y Pasos a Seguir üë£

No necesitas crear una interfaz gr√°fica. Todo el ejercicio se desarrollar√° en la terminal.

    Configuraci√≥n del Entorno:

        Aseg√∫rate de tener Python instalado.

        Instala las librer√≠as necesarias: pip install langchain langchain-google-vertexai.

        Autenticaci√≥n: No necesitas manejar archivos .env ni claves dentro del c√≥digo. Se asume que tus credenciales de Google Cloud ya est√°n configuradas como una variable de entorno en tu sistema, por lo que la autenticaci√≥n ser√° autom√°tica.

    Definir la Base de Conocimiento:

        Dentro de tu script de Python, crea una variable de texto (un string multi-l√≠nea) que simule ser un peque√±o manual de usuario o una secci√≥n de "Preguntas Frecuentes". Este ser√° el contexto que la IA usar√° para encontrar las respuestas.

        Ejemplo de contexto:

        --- Base de Conocimiento Interna ---
        1. Reseteo de Contrase√±a: El usuario debe ir a 'Configuraci√≥n > Cuenta > Olvid√© mi contrase√±a' y seguir los pasos. El enlace de reseteo se enviar√° a su correo.
        2. Problema de Arranque: Si el software no inicia, las causas comunes son: un antivirus bloqueando la aplicaci√≥n o una instalaci√≥n corrupta. La soluci√≥n es desactivar temporalmente el antivirus o reinstalar el programa.
        3. Requisitos del Sistema: Se necesita Windows 10 o superior, 8 GB de RAM y 5 GB de espacio en disco.
        --- Fin de la Base de Conocimiento ---

    Crear la Cadena (Chain) de LangChain:

        Cargar el Modelo: Inicializa el modelo ChatVertexAI para conectar con Gemini.

        Crear el Prompt Template: Dise√±a una plantilla de prompt que le d√© instrucciones claras al modelo. El prompt debe incluir dos variables de entrada: el contexto (tu base de conocimiento) y la pregunta del usuario.

            Pista: El prompt deber√≠a decirle a Gemini algo como: "Eres un asistente de soporte t√©cnico. Responde la pregunta del usuario bas√°ndote √∫nicamente en el siguiente contexto. Si la respuesta no est√° en el contexto, indica que no tienes esa informaci√≥n."

        Construir la Cadena: Une el prompt, el modelo y un StrOutputParser para que la salida sea un texto limpio.

    Probar el Asistente:

        Define una variable con una pregunta de ejemplo (ej. "No me acuerdo de mi clave, ¬øqu√© puedo hacer?").

        Invoca tu cadena de LangChain pas√°ndole tanto la base de conocimiento como la pregunta del usuario.

        Imprime en la consola la respuesta generada por Gemini.

        Realiza pruebas con diferentes preguntas, incluyendo algunas cuyas respuestas no est√©n en la base de conocimiento para ver c√≥mo reacciona el asistente.

 Divisi√≥n Proyecto Java N-Capas
Ideas de Ejercicios de Capacitaci√≥n IA
Mejora de Calidad de Foto
Significado de "btw 19teen"
Imagen Mejorada
Foto Mejorada
Conversaci√≥n con Gemini

necesito realizar un ejercicio sencillo de langchain con python ty con la ia de gemini, yo ya tenog mi clave json que me dio gcp con los servicios de vertex ia, mi clave json ya esta configurada como entorno de variable del sistema, dame un ejercicio super basico para desarrollar con langchain

Claro, aqu√≠ tienes un ejercicio s√∫per b√°sico para empezar con LangChain y Gemini, asumiendo que ya tienes tu autenticaci√≥n de GCP configurada correctamente en tu entorno.

Este script simplemente tomar√° un tema (por ejemplo, "helado") y le pedir√° a Gemini que sugiera un nombre divertido para una nueva marca. Es un "hola mundo" perfecto para probar que todo funcione.

Ejercicio B√°sico: Generador de Nombres con LangChain y Gemini

Este c√≥digo utiliza los siguientes componentes de LangChain:

    ChatVertexAI: Para conectar con el modelo de Gemini en Google Cloud Vertex AI.

    ChatPromptTemplate: Para crear una plantilla de la pregunta que le haremos al modelo.

    StrOutputParser: Para obtener la respuesta del modelo como un texto simple.

1. Instalaci√≥n de Librer√≠as

Primero, aseg√∫rate de tener instaladas las librer√≠as necesarias. Puedes hacerlo con pip:
Bash

pip install --upgrade langchain langchain-google-vertexai

2. C√≥digo Python

Crea un archivo llamado test_langchain.py y pega el siguiente c√≥digo. Est√° comentado para que entiendas qu√© hace cada l√≠nea.
Python

# -*- coding: utf-8 -*-

# Importamos las clases necesarias de LangChain
from langchain_google_vertexai import ChatVertexAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# 1. Inicializamos el modelo de Gemini
# LangChain se conectar√° a Vertex AI usando la autenticaci√≥n
# que ya tienes configurada en tu entorno.
# "gemini-1.0-pro-001" es uno de los modelos disponibles.
llm = ChatVertexAI(model_name="gemini-1.0-pro-001")

# 2. Creamos una plantilla para el prompt (la instrucci√≥n)
# Usamos llaves {} para indicar d√≥nde ir√° nuestra variable (el tema).
prompt = ChatPromptTemplate.from_messages([
    ("system", "Eres un asistente creativo experto en nombrar marcas."),
    ("user", "Sugiere un nombre divertido y corto para una nueva marca de {tema}.")
])

# 3. Creamos un "parser" para el resultado
# Esto nos asegura que la salida del modelo sea un texto simple (string).
output_parser = StrOutputParser()

# 4. Creamos la cadena (chain)
# Aqu√≠ es donde unimos los componentes en el orden en que se ejecutar√°n:
# Prompt -> Modelo LLM -> Parser de Salida
chain = prompt | llm | output_parser

# 5. Ejecutamos la cadena
# La funci√≥n "invoke" pasa la variable a nuestro prompt y ejecuta toda la cadena.
# Puedes cambiar el valor de "tema" por lo que quieras.
print("Ejecutando la cadena de LangChain...")
response = chain.invoke({"tema": "helados de frutas"})

# Imprimimos la respuesta obtenida
print("\nRespuesta de Gemini:")
print(response)

# --- Otro ejemplo ---
print("\n--- Probando con otro tema ---")
response_cafe = chain.invoke({"tema": "cafeter√≠a para programadores"})
print("\nRespuesta de Gemini:")
print(response_cafe)

3. C√≥mo Ejecutarlo

    Guarda el c√≥digo en un archivo llamado test_langchain.py.

    Abre una terminal o l√≠nea de comandos.

    Navega hasta la carpeta donde guardaste el archivo.

    Ejecuta el script con el siguiente comando:
    Bash

    python test_langchain.py

Resultado Esperado

La salida en tu terminal deber√≠a ser algo similar a esto (los nombres exactos variar√°n cada vez que lo ejecutes):

Ejecutando la cadena de LangChain...

Respuesta de Gemini:
FruityPop

--- Probando con otro tema ---

Respuesta de Gemini:
CodeBrew

Este ejercicio te confirma que tu conexi√≥n con Vertex AI funciona y que puedes construir y ejecutar una cadena b√°sica con LangChain. ¬°A partir de aqu√≠, puedes empezar a crear cadenas mucho m√°s complejas!

solo quiero que me creees una problematica para crear un readme y que lo resuelvan mis capacitantes no me des codigo ni nada, solo dame el contexto, las librerias que deberian de usar que deberia de hacer y asi pues nada de codigo dame un redme para que mis capacitantes lo desarrollen

Claro, aqu√≠ tienes una problem√°tica y su correspondiente README para que tus capacitantes la desarrollen. Est√° dise√±ado para ser un desaf√≠o pr√°ctico y enfocado en un caso de uso real.

README.md

üöÄ Ejercicio de Capacitaci√≥n: Asistente Inteligente de Soporte T√©cnico

Contexto del Problema (La Problem√°tica) üìù

Imagina que trabajas para una empresa de software que vende un producto muy popular. El equipo de soporte t√©cnico recibe cientos de correos electr√≥nicos y tickets de usuarios todos los d√≠as con preguntas, problemas y dudas.

El problema es que muchos de estos tickets son repetitivos y consumen mucho tiempo del equipo, que podr√≠a estar resolviendo problemas m√°s complejos. La gerencia ha decidido implementar una primera l√≠nea de defensa con IA para automatizar las respuestas a las preguntas m√°s frecuentes.

Objetivo del Ejercicio üéØ

Tu misi√≥n es desarrollar un script en Python que act√∫e como un "Asistente de Soporte Inteligente". Este script debe ser capaz de recibir una pregunta de un usuario sobre un problema t√©cnico y, utilizando un contexto predefinido (un peque√±o manual o base de conocimiento), generar una respuesta √∫til y amigable para el usuario.

El objetivo es que el asistente pueda responder preguntas como:

    "¬øC√≥mo puedo resetear mi contrase√±a?"

    "Mi programa no abre, ¬øqu√© hago?"

    "¬øCu√°les son los requisitos del sistema para instalar el software?"

Herramientas y Librer√≠as Requeridas üõ†Ô∏è

Para este ejercicio, deber√°s utilizar las siguientes herramientas:

    Python

    LangChain: Para orquestar el flujo de la informaci√≥n (pregunta -> prompt -> modelo -> respuesta).

    LangChain Google Vertex AI: Para conectar con el modelo de IA de Gemini.

Requisitos y Pasos a Seguir üë£

No necesitas crear una interfaz gr√°fica. Todo el ejercicio se desarrollar√° en la terminal.

    Configuraci√≥n del Entorno:

        Aseg√∫rate de tener Python instalado.

        Instala las librer√≠as necesarias (langchain, langchain-google-vertexai).

        Verifica que tu variable de entorno con la clave JSON de GCP est√© configurada correctamente.

    Definir la Base de Conocimiento:

        Dentro de tu script de Python, crea una variable de texto (un string multi-l√≠nea) que simule ser un peque√±o manual de usuario o una secci√≥n de "Preguntas Frecuentes". Este ser√° el contexto que la IA usar√° para encontrar las respuestas.

        Ejemplo de contexto:

        --- Base de Conocimiento Interna ---
        1. Reseteo de Contrase√±a: El usuario debe ir a 'Configuraci√≥n > Cuenta > Olvid√© mi contrase√±a' y seguir los pasos. El enlace de reseteo se enviar√° a su correo.
        2. Problema de Arranque: Si el software no inicia, las causas comunes son: un antivirus bloqueando la aplicaci√≥n o una instalaci√≥n corrupta. La soluci√≥n es desactivar temporalmente el antivirus o reinstalar el programa.
        3. Requisitos del Sistema: Se necesita Windows 10 o superior, 8 GB de RAM y 5 GB de espacio en disco.
        --- Fin de la Base de Conocimiento ---

    Crear la Cadena (Chain) de LangChain:

        Cargar el Modelo: Inicializa el modelo ChatVertexAI para conectar con Gemini.

        Crear el Prompt Template: Dise√±a una plantilla de prompt que le d√© instrucciones claras al modelo. El prompt debe incluir dos variables de entrada: el contexto (tu base de conocimiento) y la pregunta del usuario.

            Pista: El prompt deber√≠a decirle a Gemini algo como: "Eres un asistente de soporte t√©cnico. Responde la pregunta del usuario bas√°ndote √∫nicamente en el siguiente contexto. Si la respuesta no est√° en el contexto, indica que no tienes esa informaci√≥n."

        Construir la Cadena: Une el prompt, el modelo y un StrOutputParser para que la salida sea un texto limpio.

    Probar el Asistente:

        Define una variable con una pregunta de ejemplo (ej. "No me acuerdo de mi clave, ¬øqu√© puedo hacer?").

        Invoca tu cadena de LangChain pas√°ndole tanto la base de conocimiento como la pregunta del usuario.

        Imprime en la consola la respuesta generada por Gemini.

        Realiza pruebas con diferentes preguntas, incluyendo algunas cuyas respuestas no est√©n en la base de conocimiento para ver c√≥mo reacciona el asistente.

Criterios de √âxito (¬øCu√°ndo has terminado?) ‚úÖ

El ejercicio se considerar√° completado cuando tu script:

    Se ejecute sin errores.

    Pueda recibir una pregunta sobre un tema incluido en la base de conocimiento y genere una respuesta coherente y correcta.

    Responda de forma adecuada (ej. "No tengo informaci√≥n sobre eso") cuando se le pregunta por algo que no est√° en el contexto.

Reto Adicional (Opcional) ‚≠ê

Si terminas r√°pido, intenta modificar tu script para que, en lugar de tener una sola pregunta fija, se ejecute en un bucle while. De esta forma, el programa le pedir√° al usuario que ingrese una pregunta, la procesar√°, dar√° la respuesta y luego volver√° a pedir otra pregunta, creando una conversaci√≥n interactiva en la terminal hasta que el usuario escriba "salir".

modifica el readme, yo ya tengo mi clave json configurada como variabke de entorno del sistema no es necesario el env

¬°Entendido! He modificado el README para que sea m√°s directo y elimine cualquier menci√≥n o duda sobre la configuraci√≥n de las credenciales, asumiendo que ya est√°n listas en el sistema de tus capacitantes.

Aqu√≠ est√° la versi√≥n actualizada:

README.md

üöÄ Ejercicio de Capacitaci√≥n: Asistente Inteligente de Soporte T√©cnico

Contexto del Problema (La Problem√°tica) üìù

Imagina que trabajas para una empresa de software que vende un producto muy popular. El equipo de soporte t√©cnico recibe cientos de correos electr√≥nicos y tickets de usuarios todos los d√≠as con preguntas, problemas y dudas.

El problema es que muchos de estos tickets son repetitivos y consumen mucho tiempo del equipo, que podr√≠a estar resolviendo problemas m√°s complejos. La gerencia ha decidido implementar una primera l√≠nea de defensa con IA para automatizar las respuestas a las preguntas m√°s frecuentes.

Objetivo del Ejercicio üéØ

Tu misi√≥n es desarrollar un script en Python que act√∫e como un "Asistente de Soporte Inteligente". Este script debe ser capaz de recibir una pregunta de un usuario sobre un problema t√©cnico y, utilizando un contexto predefinido (un peque√±o manual o base de conocimiento), generar una respuesta √∫til y amigable para el usuario.

El objetivo es que el asistente pueda responder preguntas como:

    "¬øC√≥mo puedo resetear mi contrase√±a?"

    "Mi programa no abre, ¬øqu√© hago?"

    "¬øCu√°les son los requisitos del sistema para instalar el software?"

Herramientas y Librer√≠as Requeridas üõ†Ô∏è

Para este ejercicio, deber√°s utilizar las siguientes herramientas:

    Python

    LangChain: Para orquestar el flujo de la informaci√≥n (pregunta -> prompt -> modelo -> respuesta).

    LangChain Google Vertex AI: Para conectar con el modelo de IA de Gemini.

Requisitos y Pasos a Seguir üë£

No necesitas crear una interfaz gr√°fica. Todo el ejercicio se desarrollar√° en la terminal.

    Configuraci√≥n del Entorno:

        Aseg√∫rate de tener Python instalado.

        Instala las librer√≠as necesarias: pip install langchain langchain-google-vertexai.

        Autenticaci√≥n: No necesitas manejar archivos .env ni claves dentro del c√≥digo. Se asume que tus credenciales de Google Cloud ya est√°n configuradas como una variable de entorno en tu sistema, por lo que la autenticaci√≥n ser√° autom√°tica.

    Definir la Base de Conocimiento:

        Dentro de tu script de Python, crea una variable de texto (un string multi-l√≠nea) que simule ser un peque√±o manual de usuario o una secci√≥n de "Preguntas Frecuentes". Este ser√° el contexto que la IA usar√° para encontrar las respuestas.

        Ejemplo de contexto:

        --- Base de Conocimiento Interna ---
        1. Reseteo de Contrase√±a: El usuario debe ir a 'Configuraci√≥n > Cuenta > Olvid√© mi contrase√±a' y seguir los pasos. El enlace de reseteo se enviar√° a su correo.
        2. Problema de Arranque: Si el software no inicia, las causas comunes son: un antivirus bloqueando la aplicaci√≥n o una instalaci√≥n corrupta. La soluci√≥n es desactivar temporalmente el antivirus o reinstalar el programa.
        3. Requisitos del Sistema: Se necesita Windows 10 o superior, 8 GB de RAM y 5 GB de espacio en disco.
        --- Fin de la Base de Conocimiento ---

    Crear la Cadena (Chain) de LangChain:

        Cargar el Modelo: Inicializa el modelo ChatVertexAI para conectar con Gemini.

        Crear el Prompt Template: Dise√±a una plantilla de prompt que le d√© instrucciones claras al modelo. El prompt debe incluir dos variables de entrada: el contexto (tu base de conocimiento) y la pregunta del usuario.

            Pista: El prompt deber√≠a decirle a Gemini algo como: "Eres un asistente de soporte t√©cnico. Responde la pregunta del usuario bas√°ndote √∫nicamente en el siguiente contexto. Si la respuesta no est√° en el contexto, indica que no tienes esa informaci√≥n."

        Construir la Cadena: Une el prompt, el modelo y un StrOutputParser para que la salida sea un texto limpio.

    Probar el Asistente:

        Define una variable con una pregunta de ejemplo (ej. "No me acuerdo de mi clave, ¬øqu√© puedo hacer?").

        Invoca tu cadena de LangChain pas√°ndole tanto la base de conocimiento como la pregunta del usuario.

        Imprime en la consola la respuesta generada por Gemini.

        Realiza pruebas con diferentes preguntas, incluyendo algunas cuyas respuestas no est√©n en la base de conocimiento para ver c√≥mo reacciona el asistente.

Criterios de √âxito (¬øCu√°ndo has terminado?) ‚úÖ

El ejercicio se considerar√° completado cuando tu script:

    Se ejecute sin errores.

    Pueda recibir una pregunta sobre un tema incluido en la base de conocimiento y genere una respuesta coherente y correcta.

    Responda de forma adecuada (ej. "No tengo informaci√≥n sobre eso") cuando se le pregunta por algo que no est√° en el contexto.

Reto Adicional (Opcional) ‚≠ê

Si terminas r√°pido, intenta modificar tu script para que, en lugar de tener una sola pregunta fija, se ejecute en un bucle while. De esta forma, el programa le pedir√° al usuario que ingrese una pregunta, la procesar√°, dar√° la respuesta y luego volver√° a pedir otra pregunta, creando una conversaci√≥n interactiva en la terminal hasta que el usuario escriba "salir".

dame un concepto de langchain y de lo que debe de hacer en este proyecto, mas una estrucutura de ejemplo de como debreria de ser sin que sea un ejemplo de este ejercicio

¬°Claro! Aqu√≠ tienes una explicaci√≥n conceptual de LangChain, su rol en el ejercicio y una estructura de ejemplo para un proyecto diferente.

¬øQu√© es LangChain? ü§î

Piensa en LangChain como una caja de herramientas y un manual de instrucciones para construir aplicaciones con modelos de lenguaje (IA) como Gemini. No es la IA en s√≠ misma, sino el pegamento y las piezas que te permiten conectar la IA con otras fuentes de datos y darle instrucciones de manera ordenada.

Su objetivo es hacer que sea mucho m√°s f√°cil realizar tareas complejas que van m√°s all√° de un simple "pregunta y respuesta". En lugar de que tengas que escribir c√≥digo para cada peque√±o paso (formatear la pregunta, llamar a la IA, procesar la respuesta), LangChain te da "bloques" pre-construidos para que los conectes.

Los bloques m√°s comunes son:

    Models: La conexi√≥n directa con la IA (Gemini, en este caso).

    Prompts: Plantillas para darle instrucciones a la IA de forma consistente.

    Chains (Cadenas): La idea central de LangChain. Son secuencias de pasos. La cadena m√°s simple es: Prompt -> Model -> Output.

¬øQu√© Debe Hacer LangChain en Este Proyecto? üßë‚Äçüîß

En el ejercicio del "Asistente de Soporte Inteligente", LangChain act√∫a como el director de orquesta. Su trabajo es asegurarse de que la informaci√≥n fluya correctamente en el orden correcto para obtener la respuesta que queremos.

Espec√≠ficamente, su rol es:

    Tomar los Ingredientes: Recibe la pregunta del usuario ("¬øC√≥mo reseteo mi clave?") y la base de conocimiento (el texto con las soluciones).

    Preparar la Instrucci√≥n (Prompting): Usa la plantilla de prompt que creaste para mezclar los ingredientes en una instrucci√≥n clara para Gemini. El resultado es un texto final como: "Eres un asistente de soporte. Usando este contexto [aqu√≠ va la base de conocimiento], responde a esta pregunta: [aqu√≠ va la pregunta del usuario]".

    Comunicarse con la IA: Env√≠a esa instrucci√≥n finalizada al modelo de Gemini de forma estandarizada, sin que tengas que preocuparte por los detalles t√©cnicos de la API.

    Limpiar el Resultado: Recibe la respuesta completa de Gemini y, usando el StrOutputParser, la "limpia" para entregar √∫nicamente el texto de la respuesta que le mostrar√°s al usuario.

En resumen, LangChain orquesta el proceso para que t√∫ solo te preocupes por definir el contexto y la pregunta, en lugar de programar cada paso de la interacci√≥n con la IA.

Estructura de Ejemplo para Otro Proyecto (Extractor de Datos) üìë

Imagina un proyecto diferente: quieres extraer informaci√≥n estructurada de un texto no estructurado, como un correo electr√≥nico de un cliente.

Objetivo: Leer un correo y extraer autom√°ticamente el nombre del cliente, el n√∫mero de pedido y el resumen del problema en un formato organizado (como un diccionario de Python).

Una estructura de LangChain para este problema se ver√≠a as√≠:

    Entrada (Input):

        Una variable de Python que contiene el texto completo del correo electr√≥nico del cliente.

    Componente 1: El Prompt Template (ChatPromptTemplate):

        Ser√≠a una plantilla de instrucciones muy espec√≠fica.

        Instrucci√≥n: "Del siguiente texto, extrae el nombre del cliente, el n√∫mero de pedido y un resumen del problema. Responde √∫nicamente con un objeto JSON que tenga las claves nombre_cliente, numero_pedido y resumen."

        Variables: La plantilla tendr√≠a una variable para insertar el {texto_del_correo}.

    Componente 2: El Modelo (ChatVertexAI):

        El motor de Gemini, que leer√° el prompt y el correo, y entender√° que debe generar un texto con formato JSON.

    Componente 3: El Parseador de Salida (JsonOutputParser):

        Este es un bloque diferente al del ejercicio. En lugar de esperar un simple texto, este parser est√° dise√±ado para tomar la respuesta en formato JSON del modelo y convertirla autom√°ticamente en un diccionario de Python que puedes usar en tu programa.

    La Cadena (La Uni√≥n de los Componentes):

        La cadena se construir√≠a uniendo los bloques en este orden: prompt | model | json_parser

    Salida (Output):

        El resultado final no ser√≠a un texto, sino un diccionario de Python limpio y listo para usar, como este:
        Python

{
  "nombre_cliente": "Ana Garc√≠a",
  "numero_pedido": "A-54321",
  "resumen": "El paquete lleg√≥ da√±ado y falta un art√≠culo."
}


    Pueda recibir una pregunta sobre un tema incluido en la base de conocimiento y genere una respuesta coherente y correcta.

    Responda de forma adecuada (ej. "No tengo informaci√≥n sobre eso") cuando se le pregunta por algo que no est√° en el contexto.
